{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+uqK6zvn9qt5S8n3TA+5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasmine-90/am02/blob/main/11_API_Atividade_Modelos_de_Racioc%C3%ADnio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q google-generativeai"
      ],
      "metadata": {
        "id": "MRe4mFHP9Nw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Substitua 'SUA_CHAVE_DE_API' pela sua chave de API real\n",
        "genai.configure(api_key= 'SUA_CHAVE_DE_API')\n",
        "\n",
        "def listar_modelos_disponiveis():\n",
        "    \"\"\"Lista os modelos disponíveis na API e retorna um dicionário com eles.\"\"\"\n",
        "    try:\n",
        "        modelos = {}\n",
        "        models = genai.list_models()\n",
        "        print(\"\\nModelos disponíveis:\\n\")\n",
        "        for idx, model in enumerate(models):\n",
        "            print(f\"[{idx}] - Nome: {model.name}\")\n",
        "            print(f\"    Métodos suportados: {model.supported_generation_methods}\")\n",
        "            print(\"-\" * 50)\n",
        "            modelos[idx] = {\"name\": model.name, \"methods\": model.supported_generation_methods}\n",
        "        return modelos\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao listar os modelos: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "rDHQ25TK9i08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_modelo(modelos):\n",
        "    \"\"\"Permite ao usuário escolher um modelo disponível.\"\"\"\n",
        "    while True:\n",
        "        try:\n",
        "            escolha = int(input(\"\\nDigite o número do modelo que deseja usar: \"))\n",
        "            if escolha in modelos:\n",
        "                modelo = modelos[escolha]\n",
        "                print(f\"\\nModelo '{modelo['name']}' selecionado com os métodos: {modelo['methods']}\")\n",
        "                return modelo\n",
        "            else:\n",
        "                print(\"Número inválido, tente novamente.\")\n",
        "        except ValueError:\n",
        "            print(\"Entrada inválida, digite um número.\")"
      ],
      "metadata": {
        "id": "iAWZCCoZ9sGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iniciar_conversa(prompt_inicial, modelo):\n",
        "    \"\"\"Inicia uma conversa com o modelo.\"\"\"\n",
        "    if \"generateContent\" in modelo[\"methods\"]:\n",
        "        try:\n",
        "            model = genai.GenerativeModel(modelo[\"name\"])\n",
        "            chat = model.start_chat()\n",
        "            response = chat.send_message(prompt_inicial)\n",
        "            return chat, response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Ocorreu um erro ao iniciar a conversa: {e}\")\n",
        "            return None, None\n",
        "    else:\n",
        "        print(\"Este modelo não suporta 'generateContent'. Escolha outro modelo.\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "4MJzKy-O9xam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enviar_mensagem(chat, prompt):\n",
        "    \"\"\"Envia uma mensagem para a conversa existente.\"\"\"\n",
        "    try:\n",
        "        response = chat.send_message(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao enviar a mensagem: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "40TTfKte9049"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    modelos_disponiveis = listar_modelos_disponiveis()\n",
        "    modelo_selecionado = escolher_modelo(modelos_disponiveis)\n",
        "\n",
        "    if modelo_selecionado:\n",
        "        chat, resposta = iniciar_conversa(\"Olá, como você está?\", modelo_selecionado)\n",
        "        if resposta:\n",
        "            print(f\"\\nResposta do modelo: {resposta}\")\n",
        "            resposta2 = enviar_mensagem(chat, \"Me conte mais sobre você.\")\n",
        "            if resposta2:\n",
        "                print(f\"\\nResposta do modelo: {resposta2}\")"
      ],
      "metadata": {
        "id": "-ChtJcD795Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nova célula no Colab para invocar raciocínio\n",
        "if chat:\n",
        "    resposta = enviar_mensagem(chat, \"Me ajude a raciocinar sobre um problema complexo...\")\n",
        "    if resposta:\n",
        "        print(f\"\\nResposta do modelo: {resposta}\")\n"
      ],
      "metadata": {
        "id": "38OTY3Mt9-kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nova célula para simplificar e resumir a resposta anterior\n",
        "if chat and resposta:\n",
        "    prompt_simplificacao = f\"Resuma de forma clara e objetiva a seguinte resposta: '{resposta}'\"\n",
        "    resposta_resumida = enviar_mensagem(chat, prompt_simplificacao)\n",
        "\n",
        "    if resposta_resumida:\n",
        "        print(f\"\\nResposta resumida: {resposta_resumida}\")"
      ],
      "metadata": {
        "id": "qe-w41Rp-CNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta ao pedir racíocionio para a IA**\n",
        "------\n",
        "-------\n",
        "\n",
        "\n",
        "**Resposta do modelo**: Excelente! É para isso que eu estou aqui. Gosto de ajudar a desmistificar e organizar pensamentos sobre questões desafiadoras.\n",
        "\n",
        "Compartilhe comigo o problema. Quanto mais detalhes você puder fornecer, melhor poderemos abordá-lo juntos.\n",
        "\n",
        "Não se preocupe em ter tudo perfeitamente organizado de primeira. Podemos começar com o que você tem em mente e, a partir daí, posso te ajudar a:\n",
        "\n",
        "1.  **Quebrar o problema em partes menores:** Identificar os diferentes componentes, fatores ou aspectos envolvidos.\n",
        "2.  **Fazer perguntas para esclarecer:** Explorar os detalhes, as causas, os efeitos, o contexto e as interconexões.\n",
        "3.  **Considerar diferentes perspectivas:** Analisar o problema sob ângulos variados.\n",
        "4.  **Identificar restrições e recursos:** O que limita ou o que ajuda na resolução?\n",
        "5.  **Explorar possíveis abordagens ou soluções:** Pensar em caminhos diferentes para lidar com a situação.\n",
        "6.  **Organizar seus pensamentos:** Ajudar a estruturar o raciocínio de forma lógica.\n",
        "\n",
        "Lembre-se, eu não tenho a experiência humana ou a capacidade de tomar decisões no mundo real, mas posso ser um parceiro útil no processo de *pensar* sobre o problema, fornecer informações relevantes que eu possa ter acesso e ajudar a organizar as ideias.\n",
        "\n",
        "**Como você pode começar a descrever o problema?** Você pode me dizer:\n",
        "\n",
        "*   Qual é a situação ou o desafio principal?\n",
        "*   Quais são os elementos ou fatores chave envolvidos?\n",
        "*   Qual é o contexto (onde, quando, com quem)?\n",
        "*   Quais são os principais obstáculos ou dificuldades?\n",
        "*   O que você já pensou ou tentou fazer a respeito?\n",
        "*   O que você espera alcançar ou qual seria um resultado ideal?\n",
        "\n",
        "Estou pronto para ouvir e começar a raciocinar com você. Pode descrever o problema quando estiver pronto."
      ],
      "metadata": {
        "id": "YY5lyrGj-8QR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta da IA ao pedir para simplificar a resposta e devolver de forma resulmida e objetiva**\n",
        "------\n",
        "------\n",
        "Resposta resumida: Ok, aqui está um resumo claro e objetivo da resposta anterior:\n",
        "\n",
        "Ofereci ajuda para raciocinar sobre seu problema complexo. Posso auxiliar a:\n",
        "\n",
        "1.  Quebrar o problema em partes.\n",
        "2.  Esclarecer detalhes fazendo perguntas.\n",
        "3.  Considerar diferentes perspectivas.\n",
        "4.  Identificar restrições e recursos.\n",
        "5.  Explorar possíveis soluções.\n",
        "6.  Organizar seus pensamentos.\n",
        "\n",
        "Sou um parceiro no processo de *pensar*, não um tomador de decisões.\n",
        "\n",
        "Para começar, pedi que você compartilhasse o problema, sugerindo que descreva: a situação, fatores chave, contexto, obstáculos, o que já tentou e o objetivo.\n",
        "\n",
        "Estou pronto para ouvir quando você quiser descrever o problema."
      ],
      "metadata": {
        "id": "9SogfVN3_HkQ"
      }
    }
  ]
}